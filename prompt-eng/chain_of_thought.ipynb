{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain-of-Thought Prompting\n",
    "\n",
    "Chain-of-Thought (CoT) prompting enhances complex reasoning by encouraging the model to break down problems into intermediate reasoning steps. When combined with few-shot prompting, it can significantly improve performance on tasks that require multi-step reasoning before arriving at a response.\n",
    "\n",
    "## Automatic Chain-of-Thought (Auto-CoT)\n",
    "\n",
    "Traditionally, using CoT prompting with demonstrations involves manually crafting diverse and effective examples. This manual effort is time-consuming and can lead to less-than-optimal results. To address this, Zhang et al. (2022) introduced Auto-CoT, an automated approach that minimizes manual involvement. Their method uses the prompt “Let’s think step by step” to generate reasoning chains automatically for demonstrations. However, this automatic process is not immune to errors. To reduce the impact of such mistakes, the approach emphasizes the importance of diverse demonstrations.\n",
    "\n",
    "Auto-CoT operates in two main stages:\n",
    "\n",
    "1. **Question Clustering:** Questions from the dataset are grouped into clusters based on similarity or relevance.\n",
    "2. **Demonstration Sampling:** A representative question from each cluster is selected, and its reasoning chain is generated using Zero-Shot-CoT guided by simple heuristics.\n",
    "\n",
    "\n",
    "## References:\n",
    "\n",
    "* (Wei et al. (2022),)[https://arxiv.org/abs/2201.11903]\n",
    "* (OpenAI Documentation for Prompt Engineering)[https://platform.openai.com/docs/guides/prompt-engineering]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running this code on MyBind.org\n",
    "\n",
    "Note: remember that you will need to **adjust CONFIG** with **proper URL and API_KEY**!\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/GenILab-FAU/prompt-eng/HEAD?urlpath=%2Fdoc%2Ftree%2Fprompt-eng%2Fchain_of_thought.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'gemma2:2b', 'prompt': '\\nLet’s break down the requirement analysis into logical steps:\\n\\nStep 1: Define the core objectives of the study chatbot.\\nStep 2: Identify key user personas and their needs.\\nStep 3: Specify the natural language understanding capabilities required.\\nStep 4: List sources of domain-specific knowledge it should integrate with.\\nStep 5: Determine system architecture and integration points.\\nStep 6: Highlight potential technical and ethical challenges.\\n\\nNow, generate a requirement analysis based on these principles for the following scenario:\\nProvide a detailed requirement analysis for a Discord-based study chatbot system that leverages natural language understanding and domain-specific knowledge to assist users with Q&A, explanations, and study tips.\\n', 'stream': False, 'options': {'temperature': 1.0, 'num_ctx': 100, 'num_predict': 500}}\n",
      "## Requirement Analysis: Discord-Based Study Chatbot\n",
      "\n",
      "**1. Introduction:**\n",
      "\n",
      "This document outlines the requirements for a Discord-based study chatbot designed to assist users in academic learning through Q&A, explanations, and study tip suggestions.  \n",
      "\n",
      "**2. Target Audience:**\n",
      "\n",
      "* Students of all ages (high school, college, university)\n",
      "* Individuals seeking educational support across various subjects.\n",
      "\n",
      "**3. System Overview:**\n",
      "\n",
      "* The chatbot operates within the Discord platform for user interaction and content delivery. \n",
      "* Uses Natural Language Processing (NLP) to understand user input and generate appropriate responses. \n",
      "* Integrates with third-party APIs for access to external resources like study guides, tutorials, and knowledge bases.\n",
      "\n",
      "**Requirements:** \n",
      "1. **Functionality**:  The Discord bot will be able to perform the following tasks:\n",
      "    * Create an initial welcome message upon joining the server. \n",
      "    * Provide a list of available commands (e.g., /help) that users can utilize.\n",
      "    * Respond to specific user inputs and provide relevant responses or actions based on commands used. \n",
      "    * Handle errors and gracefully handle situations where commands are not recognized.\n",
      "\n",
      "Here's an example interaction:\n",
      "\n",
      "**User:**  Hi! What is the meaning of life? \n",
      "\n",
      "**Bot:** I can't answer that! But, if you want to explore philosophical concepts, I can tell you about **[insert a related topic like stoicism, existentialism, etc.]**. \n",
      "\n",
      "\n",
      "##  How does a chatbot learn from user interactions and improve over time?\n",
      "\n",
      "There are several ways chatbots can learn from user interactions:\n",
      "\n",
      "**1. Supervised Learning:**\n",
      "   *  Chatbots learn to generate responses by being trained on labeled data sets. This involves providing them with input (user queries) and their corresponding desired outputs (responses). \n",
      "   *  Algorithms, like recurrent neural networks (RNNs), are used to identify patterns and predict appropriate responses based on similar inputs in the dataset. \n",
      "\n",
      "**2. Unsupervised Learning:**\n",
      "* **Clustering:** Group users into clusters based on similarities such as age, location, purchase history, etc.\n",
      "* **Dimensionality Reduction:**  Reduce the number of variables in a dataset by identifying important features and removing or transforming others for better visualization and analysis.\n",
      "\n",
      "How can AI-powered applications leverage these techniques to improve user experience and deliver personalized recommendations? \n",
      "\n",
      "**For\n",
      "Time taken: 12.395s\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## CHAIN-OF-THOUGHT PROMPTING\n",
    "##\n",
    "import csv\n",
    "import time as timer\n",
    "from _pipeline import create_payload, model_req\n",
    "MODEL_PRESET = \"llama3.2:3b\"\n",
    "\n",
    "#### (1) Adjust the inbounding  Prompt, simulating inbounding requests from users or other systems\n",
    "MESSAGE = \"\"\"An AI-powered Discord chatbot to serve as a learning companion in a classroom. \n",
    "The bot will act as a study buddy by handling Q&A, explanations, and study tips. \n",
    "It should leverage natural language understanding and domain-specific knowledge to assist students. \n",
    "The bot must also be designed to prevent students from using it for cheating.\"\"\"\n",
    "\n",
    "#### (2) Adjust the Prompt Engineering Technique to be applied, simulating Workflow Templates\n",
    "CHAIN_OF_THOUGHT = f\"\"\"\n",
    "Let’s break down the concept of requirement analysis into logical steps:\n",
    "\n",
    "Step 1: Define the core objectives of the study chatbot.\n",
    "Step 2: Identify key user personas and their needs (user requirements).\n",
    "Step 3: Specify the natural language understanding capabilities required.\n",
    "Step 4: List sources of domain-specific knowledge it should integrate with.\n",
    "Step 5: Determine system architecture and integration points.\n",
    "\n",
    "Now, based on these principles, write a requirement analysis for the following use case: <{MESSAGE}>\n",
    "\"\"\"\n",
    "PROMPT = CHAIN_OF_THOUGHT \n",
    "\n",
    "#### (3) Configure the Model request, simulating Workflow Orchestration\n",
    "# Documentation: https://github.com/ollama/ollama/blob/main/docs/api.md\n",
    "payload = create_payload(target=\"ollama\",\n",
    "                         model=MODEL_PRESET, \n",
    "                         prompt=PROMPT, \n",
    "                         temperature=1.0, \n",
    "                         num_ctx=200, \n",
    "                         num_predict=700)\n",
    "\n",
    "### YOU DONT NEED TO CONFIGURE ANYTHING ELSE FROM THIS POINT\n",
    "# Send out to the model\n",
    "time, response = model_req(payload=payload)\n",
    "print(response)\n",
    "if time: print(f'Time taken: {time}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged data to model_logs.csv.\n"
     ]
    }
   ],
   "source": [
    "#### (OPTIONAL) LOGGING DATA TO CSV\n",
    "# Define CSV file path\n",
    "csv_file = \"model_logs.csv\"\n",
    "# Log details\n",
    "log_data = {\n",
    "    \"log_timestamp\": timer.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"prompt_method\": \"Chain-of-Thought Prompting\",\n",
    "    \"automation_level\": 0,\n",
    "    \"model_1\": payload.get(\"model\", None),\n",
    "    \"prompt_1\": payload.get(\"prompt\", None),\n",
    "    \"temperature_1\": payload.get(\"options\", {}).get(\"temperature\", None),  \n",
    "    \"num_ctx_1\": payload.get(\"options\", {}).get(\"num_ctx\", None),         \n",
    "    \"num_predict_1\": payload.get(\"options\", {}).get(\"num_predict\", None),  \n",
    "    \"response_time_1\": time,\n",
    "    \"response_1\": response,\n",
    "    \"model_2\": None,\n",
    "    \"prompt_2\": None,\n",
    "    \"temperature_2\": None,  \n",
    "    \"num_ctx_2\": None,         \n",
    "    \"num_predict_2\": None,  \n",
    "    \"response_time_2\": None,\n",
    "    \"response_2\": None,\n",
    "    \"model_3\": None,\n",
    "    \"prompt_3\": None,\n",
    "    \"temperature_3\": None,  \n",
    "    \"num_ctx_3\": None,         \n",
    "    \"num_predict_3\": None,  \n",
    "    \"response_time_3\": None,\n",
    "    \"response_3\": None,\n",
    "    \"model_4\": None,\n",
    "    \"prompt_4\": None,\n",
    "    \"temperature_4\": None,  \n",
    "    \"num_ctx_4\": None,         \n",
    "    \"num_predict_4\": None,  \n",
    "    \"response_time_4\": None,\n",
    "    \"response_4\": None,\n",
    "}\n",
    "# Save to CSV file\n",
    "write_header = False\n",
    "try:\n",
    "    with open(csv_file, \"r\") as f:\n",
    "        if not f.read():\n",
    "            write_header = True\n",
    "except FileNotFoundError:\n",
    "    write_header = True\n",
    "with open(csv_file, \"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=log_data.keys())\n",
    "    if write_header:\n",
    "        writer.writeheader()\n",
    "    writer.writerow(log_data)\n",
    "# Print confirmation\n",
    "print(f\"Logged data to {csv_file} at {timer.strftime(\"%Y-%m-%d %H:%M:%S\")}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
