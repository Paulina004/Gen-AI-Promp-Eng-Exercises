{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain-of-Thought Prompting\n",
    "\n",
    "Chain-of-Thought (CoT) prompting enhances complex reasoning by encouraging the model to break down problems into intermediate reasoning steps. When combined with few-shot prompting, it can significantly improve performance on tasks that require multi-step reasoning before arriving at a response.\n",
    "\n",
    "## Automatic Chain-of-Thought (Auto-CoT)\n",
    "\n",
    "Traditionally, using CoT prompting with demonstrations involves manually crafting diverse and effective examples. This manual effort is time-consuming and can lead to less-than-optimal results. To address this, Zhang et al. (2022) introduced Auto-CoT, an automated approach that minimizes manual involvement. Their method uses the prompt “Let’s think step by step” to generate reasoning chains automatically for demonstrations. However, this automatic process is not immune to errors. To reduce the impact of such mistakes, the approach emphasizes the importance of diverse demonstrations.\n",
    "\n",
    "Auto-CoT operates in two main stages:\n",
    "\n",
    "1. **Question Clustering:** Questions from the dataset are grouped into clusters based on similarity or relevance.\n",
    "2. **Demonstration Sampling:** A representative question from each cluster is selected, and its reasoning chain is generated using Zero-Shot-CoT guided by simple heuristics.\n",
    "\n",
    "\n",
    "## References:\n",
    "\n",
    "* (Wei et al. (2022),)[https://arxiv.org/abs/2201.11903]\n",
    "* (OpenAI Documentation for Prompt Engineering)[https://platform.openai.com/docs/guides/prompt-engineering]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running this code on MyBind.org\n",
    "\n",
    "Note: remember that you will need to **adjust CONFIG** with **proper URL and API_KEY**!\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/GenILab-FAU/prompt-eng/HEAD?urlpath=%2Fdoc%2Ftree%2Fprompt-eng%2Fchain_of_thought.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5:32b', 'prompt': '\\nLet’s break down the concept of requirement analysis into logical steps:\\n\\nStep 1: Define the core objectives of the study chatbot.\\nStep 2: Identify key user personas and their needs (user requirements).\\nStep 3: Specify the natural language understanding capabilities required.\\nStep 4: List sources of domain-specific knowledge it should integrate with.\\nStep 5: Determine system architecture and integration points.\\n\\nNow, based on these principles, write a requirement analysis for the following use case: <An AI-powered Discord chatbot to serve as a learning companion in a classroom. \\nThe bot will act as a study buddy by handling Q&A, explanations, and study tips. \\nIt should leverage natural language understanding and domain-specific knowledge to assist students. \\nThe bot must also be designed to prevent students from using it for cheating.>\\n', 'stream': False, 'options': {'temperature': 1.0, 'num_ctx': 300, 'num_predict': 700}}\n",
      "### Requirement Analysis for an AI-Powered Discord Chatbot as a Learning Companion\n",
      "\n",
      "#### Step 1: Define the Core Objectives of the Study Chatbot\n",
      "- To serve as a study buddy by handling questions and answers, providing explanations, and offering study tips.\n",
      "- To enhance student learning experiences by supplementing traditional teaching methods with interactive assistance.\n",
      "- To ensure that interactions are educational and do not lead to cheating.\n",
      "\n",
      "#### Step 2: Identify Key User Personas and Their Needs (User Requirements)\n",
      "- **Students**: Need clear explanations of complex topics, timely answers to specific questions, personalized study tips based on the subject or topic at hand. They also require a chatbot that does not provide direct test or exam answers to prevent cheating.\n",
      "- **Teachers/Professors**: Require access to reports summarizing student interactions with the bot and insights into areas where students may be struggling. Teachers must also ensure that the bot adheres to academic integrity policies.\n",
      "\n",
      "#### Step 3: Leverage Natural Language Understanding\n",
      "- The chatbot should employ advanced NLU (Natural Language Understanding) techniques to interpret various types of queries, from straightforward factual questions to more complex inquiries requiring context and reasoning.\n",
      "- The system should be capable of detecting when a student is attempting to cheat by identifying patterns in the type or frequency of questions asked.\n",
      "\n",
      "#### Step 4: Provide Tailored Responses\n",
      "- For each query, generate responses that are informative yet avoid giving away answers to test/exam-specific content. Use general explanations and examples instead.\n",
      "- Offer suggestions for additional resources such as articles, videos, or other educational materials related to the topic being discussed.\n",
      "\n",
      "#### Step 5: Ensure Security Measures Are in Place\n",
      "- Implement robust security protocols to protect sensitive information about student interactions with the chatbot.\n",
      "- Regularly update the system to address any vulnerabilities and ensure compliance with relevant privacy laws (e.g., FERPA, GDPR).\n",
      "\n",
      "### Implementation Strategy:\n",
      "\n",
      "1. **Requirement Gathering & Analysis**: Define precise requirements based on stakeholder feedback. Analyze existing systems and identify integration points.\n",
      "\n",
      "2. **Design Phase**: Develop architectural diagrams outlining how various components will interact within the larger system landscape. Create wireframes for UI/UX design if necessary.\n",
      "\n",
      "3. **Development**: Utilize Python frameworks/libraries like Flask or Django along with machine learning libraries (scikit-learn, TensorFlow) for implementing logic behind natural language understanding and processing capabilities. Employ relational databases such as PostgreSQL for storing metadata about student queries and corresponding answers.\n",
      "\n",
      "4. **Testing**: Perform thorough testing covering functional validation of the core functionalities (query handling, response generation), load testing to handle concurrent users effectively, and security assessments to mitigate potential risks associated with data breaches or unauthorized access attempts.\n",
      "\n",
      "5. **Deployment & Monitoring**: Deploy the solution onto scalable cloud infrastructure services (AWS/Azure/GCP). Set up real-time monitoring tools for tracking application performance metrics, logging errors if any occur during runtime operations, and proactively addressing issues before they escalate into significant problems affecting end-user experience.\n",
      "\n",
      "6. **Maintenance/Support:** Provide regular updates based on new feedback from educators/administrators regarding improvements needed in certain areas of the platform; continuously fine-tune algorithms driving the intelligent chatbot engine to enhance its ability to understand user intents more accurately over time.\n",
      "\n",
      "By following these steps outlined above, one can successfully design & deploy an AI-based tutoring system tailored specifically towards addressing the unique needs of K-12 students seeking supplementary academic assistance outside formal classroom settings. Such innovative solutions\n",
      "Time taken: 159.067s\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## CHAIN-OF-THOUGHT PROMPTING\n",
    "##\n",
    "import csv\n",
    "import time as timer\n",
    "from _pipeline import create_payload, model_req\n",
    "MODEL_PRESET = \"qwen2.5:32b\"\n",
    "\n",
    "\n",
    "#### (1) Adjust the inbounding  Prompt, simulating inbounding requests from users or other systems\n",
    "MESSAGE = \"\"\"An AI-powered Discord chatbot to serve as a learning companion in a classroom. \n",
    "The bot will act as a study buddy by handling Q&A, explanations, and study tips. \n",
    "It should leverage natural language understanding and domain-specific knowledge to assist students. \n",
    "The bot must also be designed to prevent students from using it for cheating.\"\"\"\n",
    "\n",
    "#### (2) Adjust the Prompt Engineering Technique to be applied, simulating Workflow Templates\n",
    "CHAIN_OF_THOUGHT = f\"\"\"\n",
    "Let’s break down the concept of requirement analysis into logical steps:\n",
    "\n",
    "Step 1: Define the core objectives of the study chatbot.\n",
    "Step 2: Identify key user personas and their needs (user requirements).\n",
    "Step 3: Specify the natural language understanding capabilities required.\n",
    "Step 4: List sources of domain-specific knowledge it should integrate with.\n",
    "Step 5: Determine system architecture and integration points.\n",
    "\n",
    "Now, based on these principles, write a requirement analysis for the following use case: <{MESSAGE}>\n",
    "\"\"\"\n",
    "PROMPT = CHAIN_OF_THOUGHT \n",
    "\n",
    "#### (3) Configure the Model request, simulating Workflow Orchestration\n",
    "# Documentation: https://github.com/ollama/ollama/blob/main/docs/api.md\n",
    "payload = create_payload(target=\"ollama\",\n",
    "                         model=MODEL_PRESET, \n",
    "                         prompt=PROMPT, \n",
    "                         temperature=1.0, \n",
    "                         num_ctx=300, \n",
    "                         num_predict=700)\n",
    "\n",
    "### YOU DONT NEED TO CONFIGURE ANYTHING ELSE FROM THIS POINT\n",
    "# Send out to the model\n",
    "time, response = model_req(payload=payload)\n",
    "print(response)\n",
    "if time: print(f'Time taken: {time}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged data to model_logs.csv for qwen2.5:32b model.\n"
     ]
    }
   ],
   "source": [
    "#### (OPTIONAL) LOGGING DATA TO CSV\n",
    "# Define CSV file path\n",
    "csv_file = \"model_logs.csv\"\n",
    "# Log details\n",
    "log_data = {\n",
    "    \"log_timestamp\": timer.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"prompt_method\": \"Chain-of-Thought Prompting\",\n",
    "    \"automation_level\": 0,\n",
    "    \"model_1\": payload.get(\"model\", None),\n",
    "    \"prompt_1\": payload.get(\"prompt\", None),\n",
    "    \"temperature_1\": payload.get(\"options\", {}).get(\"temperature\", None),  \n",
    "    \"num_ctx_1\": payload.get(\"options\", {}).get(\"num_ctx\", None),         \n",
    "    \"num_predict_1\": payload.get(\"options\", {}).get(\"num_predict\", None),  \n",
    "    \"response_time_1\": time,\n",
    "    \"response_1\": response,\n",
    "    \"model_2\": None,\n",
    "    \"prompt_2\": None,\n",
    "    \"temperature_2\": None,  \n",
    "    \"num_ctx_2\": None,         \n",
    "    \"num_predict_2\": None,  \n",
    "    \"response_time_2\": None,\n",
    "    \"response_2\": None,\n",
    "    \"model_3\": None,\n",
    "    \"prompt_3\": None,\n",
    "    \"temperature_3\": None,  \n",
    "    \"num_ctx_3\": None,         \n",
    "    \"num_predict_3\": None,  \n",
    "    \"response_time_3\": None,\n",
    "    \"response_3\": None,\n",
    "    \"model_4\": None,\n",
    "    \"prompt_4\": None,\n",
    "    \"temperature_4\": None,  \n",
    "    \"num_ctx_4\": None,         \n",
    "    \"num_predict_4\": None,  \n",
    "    \"response_time_4\": None,\n",
    "    \"response_4\": None,\n",
    "}\n",
    "# Save to CSV file\n",
    "write_header = False\n",
    "try:\n",
    "    with open(csv_file, \"r\") as f:\n",
    "        if not f.read():\n",
    "            write_header = True\n",
    "except FileNotFoundError:\n",
    "    write_header = True\n",
    "with open(csv_file, \"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=log_data.keys())\n",
    "    if write_header:\n",
    "        writer.writeheader()\n",
    "    writer.writerow(log_data)\n",
    "# Print confirmation\n",
    "print(f\"Logged data to {csv_file} for {MODEL_PRESET} model.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
