{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few-Shot Prompting\n",
    "\n",
    "Few-shot prompting can be used as a technique to enable in-context learning where we provide demonstrations in the prompt to steer the model to better performance. The demonstrations serve as conditioning for subsequent examples where we would like the model to generate a response.\n",
    "\n",
    "## References:\n",
    "* [Touvron et al. 2023](https://arxiv.org/pdf/2302.13971.pdf): present few shot properties  when models were scaled to a sufficient size\n",
    "* [Kaplan et al., 2020](https://arxiv.org/abs/2001.08361)\n",
    "* [Brown et al. 2020](https://arxiv.org/abs/2005.14165)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running this code on MyBind.org\n",
    "\n",
    "Note: remember that you will need to **adjust CONFIG** with **proper URL and API_KEY**!\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/GenILab-FAU/prompt-eng/HEAD?urlpath=%2Fdoc%2Ftree%2Fprompt-eng%2Ffew_shots.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.2:3b', 'prompt': 'You are a math teacher. If student asked 1 + 1 you answer 2. If student ask 987 * 2 you answer only 1974. Student asked; provide the result only: \\nCalculate 984 * log(2)', 'stream': False, 'options': {'temperature': 1.0, 'num_ctx': 100, 'num_predict': 100}}\n",
      "Since I've learned to be more... concise in my responses, I'll just give the numerical result:\n",
      "\n",
      "1968\n",
      "Time taken: 4.547s\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## FEW-SHOT PROMPTING\n",
    "##\n",
    "import csv\n",
    "import time as timer\n",
    "from _pipeline import create_payload, model_req\n",
    "\n",
    "#### (1) Adjust the inbounding  Prompt, simulating inbounding requests from users or other systems\n",
    "MESSAGE = \"Provide a detailed requirement analysis for a Discord-based study chatbot system that leverages natural language understanding and domain-specific knowledge to assist users with Q&A, explanations, and study tips.\"\n",
    "\n",
    "#### (2) Adjust the Prompt Engineering Technique to be applied, simulating Workflow Templates\n",
    "FEW_SHOT = \"\"\"You are a software engineer. \n",
    "            If asked to create a requirement analysis for a customer support bot, you would write requirements related to how it needs intent recogition, response personalization, and ticket management. \n",
    "            If you were asked to write requirement analysis for a health advice bot, you would write requirements related to how it needs symptom analysis, treatment recommendations, and appointment scheduling. \n",
    "            Now, you are asked about the following system. What would you write?\"\"\"\n",
    "PROMPT = FEW_SHOT + '\\n' + MESSAGE \n",
    "\n",
    "#### (3) Configure the Model request, simulating Workflow Orchestration\n",
    "# Documentation: https://github.com/ollama/ollama/blob/main/docs/api.md\n",
    "payload = create_payload(target=\"ollama\",\n",
    "                         model=\"llama3.2:3b\", \n",
    "                         prompt=PROMPT, \n",
    "                         temperature=1.0, \n",
    "                         num_ctx=200, \n",
    "                         num_predict=500)\n",
    "\n",
    "#### (4) Send out to the model\n",
    "time, response = model_req(payload=payload)\n",
    "print(response)\n",
    "if time: print(f'Time taken: {time}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### (OPTIONAL) LOGGING DATA TO CSV\n",
    "# Define CSV file path\n",
    "csv_file = \"model_logs.csv\"\n",
    "# Log details\n",
    "log_data = {\n",
    "    \"log_timestamp\": timer.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"prompt_method\": \"Zero-Shot Prompting\",\n",
    "    \"automation_level\": 0,\n",
    "    \"model_1\": payload.get(\"model\", None),\n",
    "    \"prompt_1\": payload.get(\"prompt\", None),\n",
    "    \"temperature_1\": payload.get(\"options\", {}).get(\"temperature\", None),  \n",
    "    \"num_ctx_1\": payload.get(\"options\", {}).get(\"num_ctx\", None),         \n",
    "    \"num_predict_1\": payload.get(\"options\", {}).get(\"num_predict\", None),  \n",
    "    \"response_time_1\": time,\n",
    "    \"response_1\": response,\n",
    "    \"model_2\": None,\n",
    "    \"prompt_2\": None,\n",
    "    \"temperature_2\": None,  \n",
    "    \"num_ctx_2\": None,         \n",
    "    \"num_predict_2\": None,  \n",
    "    \"response_time_2\": None,\n",
    "    \"response_2\": None,\n",
    "    \"model_3\": None,\n",
    "    \"prompt_3\": None,\n",
    "    \"temperature_3\": None,  \n",
    "    \"num_ctx_3\": None,         \n",
    "    \"num_predict_3\": None,  \n",
    "    \"response_time_3\": None,\n",
    "    \"response_3\": None,\n",
    "    \"model_4\": None,\n",
    "    \"prompt_4\": None,\n",
    "    \"temperature_4\": None,  \n",
    "    \"num_ctx_4\": None,         \n",
    "    \"num_predict_4\": None,  \n",
    "    \"response_time_4\": None,\n",
    "    \"response_4\": None,\n",
    "}\n",
    "# Save to CSV file\n",
    "write_header = False\n",
    "try:\n",
    "    with open(csv_file, \"r\") as f:\n",
    "        if not f.read():\n",
    "            write_header = True\n",
    "except FileNotFoundError:\n",
    "    write_header = True\n",
    "with open(csv_file, \"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=log_data.keys())\n",
    "    if write_header:\n",
    "        writer.writeheader()\n",
    "    writer.writerow(log_data)\n",
    "# Print confirmation\n",
    "print(f\"Logged data to {csv_file}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to improve it?\n",
    "\n",
    "Following the findings from [Min et al. (2022)](https://arxiv.org/abs/2202.12837), here are a few more tips about demonstrations/exemplars when doing few-shot:\n",
    "\n",
    "* \"the label space and the distribution of the input text specified by the demonstrations are both important (regardless of whether the labels are correct for individual inputs)\"\n",
    "* the format you use also plays a key role in performance, even if you just use random labels, this is much better than no labels at all.\n",
    "* additional results show that selecting random labels from a true distribution of labels (instead of a uniform distribution) also helps."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
